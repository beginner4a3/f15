{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "intro",
            "metadata": {},
            "source": [
                "# IndicF5 Streaming TTS (Speed Optimized)\n",
                "\n",
                "**Optimizations:**\n",
                "- üî• Model warm-up\n",
                "- ‚ö° **NFE Steps = 16** (default 32) ‚Üí 2x faster!\n",
                "- üöÄ Sway sampling = -1\n",
                "\n",
                "**Setup:** T4 GPU + HF access"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "gpu",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "assert torch.cuda.is_available(), '‚ùå GPU!'\n",
                "print(f'‚úÖ GPU: {torch.cuda.get_device_name(0)}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "install",
            "metadata": {},
            "outputs": [],
            "source": [
                "# RESTART RUNTIME AFTER\n",
                "!pip uninstall -y numpy scipy -q\n",
                "!pip install numpy==1.26.4 scipy -q\n",
                "!pip install 'transformers<4.50' accelerate -q\n",
                "!pip install git+https://github.com/ai4bharat/IndicF5.git -q\n",
                "!pip install gradio torchcodec soundfile requests -q\n",
                "print('‚ö†Ô∏è RESTART RUNTIME!')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "login",
            "metadata": {},
            "outputs": [],
            "source": [
                "from huggingface_hub import notebook_login\n",
                "notebook_login()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "app",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch, gradio as gr, tempfile, soundfile as sf, numpy as np, requests, io, re, os, time\n",
                "from transformers import AutoModel\n",
                "\n",
                "# SPEED SETTINGS\n",
                "NFE_STEPS = 16  # Default 32 - lower = faster but less quality (try 8-16 for speed)\n",
                "SWAY_COEF = -1  # Sway sampling coefficient for speed\n",
                "\n",
                "torch.backends.cudnn.benchmark = True\n",
                "\n",
                "def load_audio_url(url):\n",
                "    r = requests.get(url)\n",
                "    data, sr = sf.read(io.BytesIO(r.content))\n",
                "    return sr, (data * 32768).astype(np.int16) if data.dtype == np.float64 else data\n",
                "\n",
                "def split_sentences(text):\n",
                "    parts = re.split(r'[.!?‡•§‡••\\n]+', text)\n",
                "    return [p.strip() for p in parts if p.strip()]\n",
                "\n",
                "EXAMPLES = [\n",
                "    {'name': 'PAN_F (Happy)', 'url': 'https://github.com/AI4Bharat/IndicF5/raw/refs/heads/main/prompts/PAN_F_HAPPY_00002.wav',\n",
                "     'ref_text': '‡®á‡©±‡®ï ‡®ó‡©ç‡®∞‡®æ‡®π‡®ï ‡®®‡©á ‡®∏‡®æ‡®°‡©Ä ‡®¨‡©á‡®Æ‡®ø‡®∏‡®æ‡®≤ ‡®∏‡©á‡®µ‡®æ ‡®¨‡®æ‡®∞‡©á ‡®¶‡®ø‡®≤‡©ã‡®Ç‡®ó‡®µ‡®æ‡®π‡©Ä ‡®¶‡®ø‡©±‡®§‡©Ä ‡®ú‡®ø‡®∏ ‡®®‡®æ‡®≤ ‡®∏‡®æ‡®®‡©Ç‡©∞ ‡®Ö‡®®‡©∞‡®¶ ‡®Æ‡®π‡®ø‡®∏‡©Ç‡®∏ ‡®π‡©ã‡®á‡®Ü‡•§',\n",
                "     'synth': '‡§Æ‡•à‡§Ç ‡§¨‡§ø‡§®‡§æ ‡§ï‡§ø‡§∏‡•Ä ‡§ö‡§ø‡§Ç‡§§‡§æ ‡§ï‡•á ‡§Ö‡§™‡§®‡•á ‡§¶‡•ã‡§∏‡•ç‡§§‡•ã‡§Ç ‡§ï‡•ã ‡§Ö‡§™‡§®‡•á ‡§ë‡§ü‡•ã‡§Æ‡•ã‡§¨‡§æ‡§á‡§≤ ‡§è‡§ï‡•ç‡§∏‡§™‡§∞‡•ç‡§ü ‡§ï‡•á ‡§™‡§æ‡§∏ ‡§≠‡•á‡§ú ‡§¶‡•á‡§§‡§æ ‡§π‡•Ç‡§Å ‡§ï‡•ç‡§Ø‡•ã‡§Ç‡§ï‡§ø ‡§Æ‡•à‡§Ç ‡§ú‡§æ‡§®‡§§‡§æ ‡§π‡•Ç‡§Å ‡§ï‡§ø ‡§µ‡§π ‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§â‡§®‡§ï‡•Ä ‡§∏‡§≠‡•Ä ‡§ú‡§∞‡•Ç‡§∞‡§§‡•ã‡§Ç ‡§™‡§∞ ‡§ñ‡§∞‡§æ ‡§â‡§§‡§∞‡•á‡§ó‡§æ‡•§'},\n",
                "    {'name': 'TAM_F (Happy)', 'url': 'https://github.com/AI4Bharat/IndicF5/raw/refs/heads/main/prompts/TAM_F_HAPPY_00001.wav',\n",
                "     'ref_text': '‡Æ®‡Ææ‡Æ©‡Øç ‡Æ®‡ØÜ‡Æ©‡Æö‡Øç‡Æö ‡ÆÆ‡Ææ‡Æ§‡Æø‡Æ∞‡Æø‡ÆØ‡Øá ‡ÆÖ‡ÆÆ‡Øá‡Æö‡Ææ‡Æ©‡Øç‡Æ≤ ‡Æ™‡ØÜ‡Æ∞‡Æø‡ÆØ ‡Æ§‡Æ≥‡Øç‡Æ≥‡ØÅ‡Æ™‡Æü‡Æø ‡Æµ‡Æ®‡Øç‡Æ§‡Æø‡Æ∞‡ØÅ‡Æï‡Øç‡Æï‡ØÅ. ‡Æï‡ÆÆ‡Øç‡ÆÆ‡Æø ‡Æï‡Ææ‡Æö‡ØÅ‡Æï‡Øç‡Æï‡Øá ‡ÆÖ‡Æ®‡Øç‡Æ§‡Æ™‡Øç ‡Æ™‡ØÅ‡Æ§‡ØÅ ‡Æö‡Øá‡ÆÆ‡Øç‡Æö‡Æô‡Øç ‡ÆÆ‡Ææ‡Æü‡Æ≤ ‡Æµ‡Ææ‡Æô‡Øç‡Æï‡Æø‡Æü‡Æ≤‡Ææ‡ÆÆ‡Øç.',\n",
                "     'synth': '‡¥≠‡¥ï‡µç‡¥∑‡¥£‡¥§‡µç‡¥§‡¥ø‡¥®‡µç ‡¥∂‡µá‡¥∑‡¥Ç ‡¥§‡µà‡¥∞‡µç ‡¥∏‡¥æ‡¥¶‡¥Ç ‡¥ï‡¥¥‡¥ø‡¥ö‡µç‡¥ö‡¥æ‡µΩ ‡¥í‡¥∞‡µÅ ‡¥â‡¥∑‡¥æ‡¥±‡¥æ‡¥£‡µç!'},\n",
                "    {'name': 'MAR_F (WIKI)', 'url': 'https://github.com/AI4Bharat/IndicF5/raw/refs/heads/main/prompts/MAR_F_WIKI_00001.wav',\n",
                "     'ref_text': '‡§¶‡§ø‡§ó‡§Ç‡§ü‡§∞‡§æ‡§µ‡•ç‡§¶‡§æ‡§∞‡•á ‡§Ö‡§Ç‡§§‡§∞‡§æ‡§≥ ‡§ï‡§ï‡•ç‡§∑‡•á‡§§‡§≤‡§æ ‡§ï‡§ö‡§∞‡§æ ‡§ö‡§ø‡§®‡•ç‡§π‡§ø‡§§ ‡§ï‡§∞‡§£‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä ‡§™‡•ç‡§∞‡§Ø‡§§‡•ç‡§® ‡§ï‡•á‡§≤‡•á ‡§ú‡§æ‡§§ ‡§Ü‡§π‡•á.',\n",
                "     'synth': '‡§™‡•ç‡§∞‡§æ‡§∞‡§Ç‡§≠‡§ø‡§ï ‡§Ö‡§Ç‡§ï‡•Å‡§∞ ‡§õ‡•á‡§¶‡§ï. ‡§Æ‡•Ä ‡§∏‡•ã‡§≤‡§æ‡§™‡•Ç‡§∞ ‡§ú‡§ø‡§≤‡•ç‡§π‡•ç‡§Ø‡§æ‡§§‡•Ä‡§≤ ‡§Æ‡§æ‡§≥‡§∂‡§ø‡§∞‡§∏ ‡§§‡§æ‡§≤‡•Å‡§ï‡•ç‡§Ø‡§æ‡§§‡•Ä‡§≤ ‡§∂‡•á‡§§‡§ï‡§∞‡•Ä ‡§ó‡§£‡§™‡§§ ‡§™‡§æ‡§ü‡•Ä‡§≤ ‡§¨‡•ã‡§≤‡§§‡•ã‡§Ø.'},\n",
                "    {'name': 'MAR_M (WIKI)', 'url': 'https://github.com/AI4Bharat/IndicF5/raw/refs/heads/main/prompts/MAR_M_WIKI_00001.wav',\n",
                "     'ref_text': '‡§Ø‡§æ ‡§™‡•ç‡§∞‡§•‡§æ‡§≤‡§æ ‡§è‡§ï‡•ã‡§£‡•Ä‡§∏‡§∂‡•á ‡§™‡§Ç‡§ö‡§æ‡§§‡§∞ ‡§à‡§∏‡§µ‡•Ä ‡§™‡§æ‡§∏‡•Ç‡§® ‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§¶‡§Ç‡§° ‡§∏‡§Ç‡§π‡§ø‡§§‡§æ‡§ö‡•Ä ‡§ß‡§æ‡§∞‡§æ ‡§ö‡§æ‡§∞‡§∂‡•á ‡§Ö‡§†‡•ç‡§†‡§æ‡§µ‡•Ä‡§∏ ‡§Ü‡§£‡§ø ‡§ö‡§æ‡§∞‡§∂‡•á ‡§è‡§ï‡•ã‡§£‡§§‡•Ä‡§∏‡§ö‡•ç‡§Ø‡§æ ‡§Ö‡§®‡•ç‡§§‡§∞‡•ç‡§ó‡§§ ‡§®‡§ø‡§∑‡•á‡§ß ‡§ï‡•á‡§≤‡§æ.',\n",
                "     'synth': '‡§ú‡•Ä‡§µ‡§æ‡§£‡•Ç ‡§ï‡§∞‡§™‡§æ. ‡§Æ‡•Ä ‡§Ö‡§π‡§Æ‡§¶‡§®‡§ó‡§∞ ‡§ú‡§ø‡§≤‡•ç‡§π‡•ç‡§Ø‡§æ‡§§‡•Ä‡§≤ ‡§∞‡§æ‡§π‡•Å‡§∞‡•Ä ‡§ó‡§æ‡§µ‡§æ‡§§‡•Ç‡§® ‡§¨‡§æ‡§≥‡§æ‡§∏‡§æ‡§π‡•á‡§¨ ‡§ú‡§æ‡§ß‡§µ ‡§¨‡•ã‡§≤‡§§‡•ã‡§Ø.'},\n",
                "    {'name': 'KAN_F (Happy)', 'url': 'https://github.com/AI4Bharat/IndicF5/raw/refs/heads/main/prompts/KAN_F_HAPPY_00001.wav',\n",
                "     'ref_text': '‡≤®‡≤Æ‡≥ç‚Äå ‡≤´‡≥ç‡≤∞‡≤ø‡≤ú‡≥ç‡≤ú‡≤≤‡≥ç‡≤≤‡≤ø  ‡≤ï‡≥Ç‡≤≤‡≤ø‡≤Ç‡≤ó‡≥ç‚Äå ‡≤∏‡≤Æ‡≤∏‡≥ç‡≤Ø‡≥Ü ‡≤Ü‡≤ó‡≤ø ‡≤®‡≤æ‡≤®‡≥ç‚Äå ‡≤≠‡≤æ‡≤≥ ‡≤¶‡≤ø‡≤®‡≤¶‡≤ø‡≤Ç‡≤¶ ‡≤í‡≤¶‡≥ç‡≤¶‡≤æ‡≤°‡≥ç‡≤§‡≤ø‡≤¶‡≥ç‡≤¶‡≥Ü.',\n",
                "     'synth': '‡¶ö‡ßá‡¶®‡ßç‡¶®‡¶æ‡¶á‡¶Ø‡¶º‡ßá‡¶∞ ‡¶∂‡ßá‡¶Ø‡¶º‡¶æ‡¶∞‡ßá‡¶∞ ‡¶Ö‡¶ü‡ßã‡¶∞ ‡¶Ø‡¶æ‡¶§‡ßç‡¶∞‡ßÄ‡¶¶‡ßá‡¶∞ ‡¶Æ‡¶ß‡ßç‡¶Ø‡ßá ‡¶ñ‡¶æ‡¶¨‡¶æ‡¶∞ ‡¶≠‡¶æ‡¶ó ‡¶ï‡¶∞‡ßá ‡¶ñ‡¶æ‡¶ì‡¶Ø‡¶º‡¶æ‡¶ü‡¶æ ‡¶Ü‡¶Æ‡¶æ‡¶∞ ‡¶ï‡¶æ‡¶õ‡ßá ‡¶Æ‡¶® ‡¶ñ‡ßÅ‡¶¨ ‡¶≠‡¶æ‡¶≤‡ßã ‡¶ï‡¶∞‡ßá ‡¶¶‡ßá‡¶ì‡¶Ø‡¶º‡¶æ ‡¶è‡¶ï‡¶ü‡¶æ ‡¶¨‡¶ø‡¶∑‡¶Ø‡¶º‡•§'},\n",
                "]\n",
                "\n",
                "print('Loading examples...')\n",
                "for ex in EXAMPLES:\n",
                "    ex['sr'], ex['data'] = load_audio_url(ex['url'])\n",
                "    tmp = tempfile.NamedTemporaryFile(suffix='.wav', delete=False)\n",
                "    sf.write(tmp.name, ex['data'], ex['sr'])\n",
                "    ex['ref_path'] = tmp.name\n",
                "print(f'‚úÖ {len(EXAMPLES)} examples loaded')\n",
                "\n",
                "print('Loading IndicF5...')\n",
                "model = AutoModel.from_pretrained('ai4bharat/IndicF5', trust_remote_code=True).to('cuda')\n",
                "print('‚úÖ Model loaded')\n",
                "\n",
                "# Patch the infer settings for speed\n",
                "try:\n",
                "    from f5_tts.infer import utils_infer\n",
                "    # Patch default NFE steps\n",
                "    original_infer = utils_infer.infer_process\n",
                "    def fast_infer(*args, nfe_step=NFE_STEPS, sway_sampling_coef=SWAY_COEF, **kwargs):\n",
                "        return original_infer(*args, nfe_step=nfe_step, sway_sampling_coef=sway_sampling_coef, **kwargs)\n",
                "    utils_infer.infer_process = fast_infer\n",
                "    print(f'‚úÖ Patched infer: nfe_step={NFE_STEPS}, sway={SWAY_COEF}')\n",
                "except Exception as e:\n",
                "    print(f'‚ö†Ô∏è Could not patch infer settings: {e}')\n",
                "\n",
                "# WARM-UP\n",
                "print('üî• Warming up...')\n",
                "warmup_start = time.time()\n",
                "with torch.inference_mode():\n",
                "    _ = model('Hello', ref_audio_path=EXAMPLES[0]['ref_path'], ref_text=EXAMPLES[0]['ref_text'])\n",
                "print(f'‚úÖ Warm-up done in {time.time() - warmup_start:.1f}s')\n",
                "\n",
                "current_ref_path = [None]\n",
                "\n",
                "def synthesize_streaming(text, ref_audio, ref_text):\n",
                "    if not text or ref_audio is None or not ref_text:\n",
                "        return\n",
                "    \n",
                "    sr, data = ref_audio\n",
                "    sentences = split_sentences(text)\n",
                "    print(f'[STREAM] {len(sentences)} sentences')\n",
                "    \n",
                "    if current_ref_path[0] and os.path.exists(current_ref_path[0]):\n",
                "        ref_path = current_ref_path[0]\n",
                "    else:\n",
                "        ref_file = tempfile.NamedTemporaryFile(suffix='.wav', delete=False)\n",
                "        sf.write(ref_file.name, data, sr)\n",
                "        ref_path = ref_file.name\n",
                "    \n",
                "    for i, sentence in enumerate(sentences):\n",
                "        start = time.time()\n",
                "        print(f'[{i+1}/{len(sentences)}] Generating...')\n",
                "        \n",
                "        with torch.inference_mode():\n",
                "            chunk = model(sentence, ref_audio_path=ref_path, ref_text=ref_text)\n",
                "        \n",
                "        if chunk.dtype == np.int16:\n",
                "            chunk = chunk.astype(np.float32) / 32768.0\n",
                "        \n",
                "        chunk_file = tempfile.NamedTemporaryFile(suffix='.wav', delete=False)\n",
                "        sf.write(chunk_file.name, chunk, 24000)\n",
                "        \n",
                "        elapsed = time.time() - start\n",
                "        audio_len = len(chunk) / 24000\n",
                "        print(f'[{i+1}/{len(sentences)}] {elapsed:.1f}s for {audio_len:.1f}s audio (RTF: {elapsed/audio_len:.2f})')\n",
                "        yield chunk_file.name\n",
                "    \n",
                "    print('[STREAM] Complete!')\n",
                "\n",
                "def load_example(name):\n",
                "    ex = next((e for e in EXAMPLES if e['name'] == name), None)\n",
                "    if ex:\n",
                "        current_ref_path[0] = ex['ref_path']\n",
                "        return ((ex['sr'], ex['data']), ex['ref_text'], ex['synth'])\n",
                "    return (None, '', '')\n",
                "\n",
                "with gr.Blocks(title='IndicF5 Fast') as app:\n",
                "    gr.Markdown('# üöÄ IndicF5 Streaming TTS (Speed Optimized)')\n",
                "    gr.Markdown(f'**Settings:** NFE={NFE_STEPS} (default 32) | Target: ~4-6s per 4s audio')\n",
                "    \n",
                "    dd = gr.Dropdown([e['name'] for e in EXAMPLES], label='üìÇ Choose example')\n",
                "    \n",
                "    with gr.Row():\n",
                "        with gr.Column():\n",
                "            txt = gr.Textbox(label='Text to Synthesize', lines=4)\n",
                "            ref = gr.Audio(label='Reference Audio', type='numpy')\n",
                "            ref_txt = gr.Textbox(label='Reference Text', lines=2)\n",
                "            btn = gr.Button('üé§ Generate', variant='primary')\n",
                "        out = gr.Audio(label='Output', streaming=True, autoplay=True)\n",
                "    \n",
                "    dd.change(load_example, [dd], [ref, ref_txt, txt])\n",
                "    btn.click(synthesize_streaming, [txt, ref, ref_txt], [out])\n",
                "\n",
                "app.launch(share=True, debug=True)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}