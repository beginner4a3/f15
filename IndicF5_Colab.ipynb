{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "intro",
            "metadata": {},
            "source": [
                "# IndicF5 Streaming TTS Demo\n",
                "\n",
                "**Features:** üéß Streaming audio - plays progressively!\n",
                "\n",
                "**Setup:** T4 GPU + HF access to https://huggingface.co/ai4bharat/IndicF5"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "gpu",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "assert torch.cuda.is_available(), '‚ùå GPU!'\n",
                "print(f'‚úÖ GPU: {torch.cuda.get_device_name(0)}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "install",
            "metadata": {},
            "outputs": [],
            "source": [
                "# RESTART RUNTIME AFTER THIS\n",
                "!pip uninstall -y numpy scipy -q\n",
                "!pip install numpy==1.26.4 scipy -q\n",
                "!pip install 'transformers<4.50' accelerate -q\n",
                "!pip install git+https://github.com/ai4bharat/IndicF5.git -q\n",
                "!pip install gradio torchcodec soundfile requests -q\n",
                "print('‚ö†Ô∏è RESTART RUNTIME!')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "login",
            "metadata": {},
            "outputs": [],
            "source": [
                "from huggingface_hub import notebook_login\n",
                "notebook_login()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "app",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch, gradio as gr, tempfile, soundfile as sf, numpy as np, requests, io, re, os\n",
                "from transformers import AutoModel\n",
                "\n",
                "def load_audio_url(url):\n",
                "    r = requests.get(url)\n",
                "    data, sr = sf.read(io.BytesIO(r.content))\n",
                "    return sr, (data * 32768).astype(np.int16) if data.dtype == np.float64 else data\n",
                "\n",
                "def split_sentences(text):\n",
                "    parts = re.split(r'[.!?‡•§‡••\\n]+', text)\n",
                "    return [p.strip() for p in parts if p.strip()]\n",
                "\n",
                "EXAMPLES = [\n",
                "    {'name': 'PAN_F', 'url': 'https://github.com/AI4Bharat/IndicF5/raw/refs/heads/main/prompts/PAN_F_HAPPY_00002.wav',\n",
                "     'ref_text': '‡®á‡©±‡®ï ‡®ó‡©ç‡®∞‡®æ‡®π‡®ï ‡®®‡©á ‡®∏‡®æ‡®°‡©Ä ‡®¨‡©á‡®Æ‡®ø‡®∏‡®æ‡®≤ ‡®∏‡©á‡®µ‡®æ ‡®¨‡®æ‡®∞‡©á ‡®¶‡®ø‡®≤‡©ã‡®Ç‡®ó‡®µ‡®æ‡®π‡©Ä ‡®¶‡®ø‡©±‡®§‡©Ä‡•§',\n",
                "     'synth': '‡§Æ‡•à‡§Ç ‡§¨‡§ø‡§®‡§æ ‡§ï‡§ø‡§∏‡•Ä ‡§ö‡§ø‡§Ç‡§§‡§æ ‡§ï‡•á ‡§Ö‡§™‡§®‡•á ‡§¶‡•ã‡§∏‡•ç‡§§‡•ã‡§Ç ‡§ï‡•ã ‡§≠‡•á‡§ú‡§§‡§æ ‡§π‡•Ç‡§Å‡•§ ‡§µ‡§π ‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§Æ‡§¶‡§¶ ‡§ï‡§∞‡•á‡§ó‡§æ‡•§ ‡§Ø‡§π ‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ö‡•ç‡§õ‡•Ä ‡§¨‡§æ‡§§ ‡§π‡•à‡•§'},\n",
                "]\n",
                "\n",
                "print('Loading examples...')\n",
                "for ex in EXAMPLES:\n",
                "    ex['sr'], ex['data'] = load_audio_url(ex['url'])\n",
                "\n",
                "print('Loading IndicF5...')\n",
                "model = AutoModel.from_pretrained('ai4bharat/IndicF5', trust_remote_code=True).to('cuda')\n",
                "print('‚úÖ Ready!')\n",
                "\n",
                "# FIXED STREAMING: Yield individual WAV file chunks\n",
                "def synthesize_streaming(text, ref_audio, ref_text):\n",
                "    if not text or ref_audio is None or not ref_text:\n",
                "        return\n",
                "    \n",
                "    sr, data = ref_audio\n",
                "    sentences = split_sentences(text)\n",
                "    print(f'[STREAM] {len(sentences)} sentences')\n",
                "    \n",
                "    # Save ref audio\n",
                "    ref_file = tempfile.NamedTemporaryFile(suffix='.wav', delete=False)\n",
                "    sf.write(ref_file.name, data, sr)\n",
                "    ref_path = ref_file.name\n",
                "    \n",
                "    for i, sentence in enumerate(sentences):\n",
                "        print(f'[{i+1}/{len(sentences)}] {sentence[:40]}...')\n",
                "        \n",
                "        # Generate audio for this sentence\n",
                "        chunk = model(sentence, ref_audio_path=ref_path, ref_text=ref_text)\n",
                "        \n",
                "        if chunk.dtype == np.int16:\n",
                "            chunk = chunk.astype(np.float32) / 32768.0\n",
                "        \n",
                "        # Save chunk to temp WAV file\n",
                "        chunk_file = tempfile.NamedTemporaryFile(suffix='.wav', delete=False)\n",
                "        sf.write(chunk_file.name, chunk, 24000)\n",
                "        \n",
                "        print(f'[{i+1}] Yielding chunk: {len(chunk)} samples')\n",
                "        \n",
                "        # Yield the WAV file path (Gradio appends these)\n",
                "        yield chunk_file.name\n",
                "    \n",
                "    print('[STREAM] Done!')\n",
                "\n",
                "def load_example(name):\n",
                "    ex = next((e for e in EXAMPLES if e['name'] == name), None)\n",
                "    return ((ex['sr'], ex['data']), ex['ref_text'], ex['synth']) if ex else (None, '', '')\n",
                "\n",
                "with gr.Blocks(title='IndicF5') as app:\n",
                "    gr.Markdown('# üéß IndicF5 Streaming TTS')\n",
                "    \n",
                "    dd = gr.Dropdown([e['name'] for e in EXAMPLES], label='Example')\n",
                "    \n",
                "    with gr.Row():\n",
                "        with gr.Column():\n",
                "            txt = gr.Textbox(label='Text', lines=3)\n",
                "            ref = gr.Audio(label='Reference Audio', type='numpy')\n",
                "            ref_txt = gr.Textbox(label='Reference Text')\n",
                "            btn = gr.Button('üé§ Generate', variant='primary')\n",
                "        \n",
                "        # STREAMING: yield file paths, Gradio appends them\n",
                "        out = gr.Audio(label='Output', streaming=True, autoplay=True)\n",
                "    \n",
                "    dd.change(load_example, [dd], [ref, ref_txt, txt])\n",
                "    btn.click(synthesize_streaming, [txt, ref, ref_txt], [out])\n",
                "\n",
                "app.launch(share=True, debug=True)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}