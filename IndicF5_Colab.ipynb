{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "intro",
            "metadata": {},
            "source": [
                "# IndicF5 Streaming TTS Demo\n",
                "\n",
                "**Features:**\n",
                "- üéß **Streaming audio** - Playback starts after first sentence!\n",
                "- üìù **Examples included** - Pre-loaded reference audios\n",
                "\n",
                "**Prerequisites:**\n",
                "1. GPU runtime: Runtime ‚Üí Change runtime type ‚Üí T4 GPU\n",
                "2. Request access: https://huggingface.co/ai4bharat/IndicF5\n",
                "3. Get HF token: https://huggingface.co/settings/tokens"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "gpu_check",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "if not torch.cuda.is_available():\n",
                "    raise RuntimeError('‚ùå GPU not available!')\n",
                "print(f'‚úÖ GPU: {torch.cuda.get_device_name(0)}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "install",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install (RESTART RUNTIME AFTER)\n",
                "!pip uninstall -y numpy scipy -q\n",
                "!pip install numpy==1.26.4 scipy -q\n",
                "!pip install 'transformers<4.50' accelerate -q\n",
                "!pip install git+https://github.com/ai4bharat/IndicF5.git -q\n",
                "!pip install gradio torchcodec soundfile requests -q\n",
                "print('\\n‚ö†Ô∏è RESTART RUNTIME! Then skip this cell.')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "hf_login",
            "metadata": {},
            "outputs": [],
            "source": [
                "from huggingface_hub import notebook_login\n",
                "notebook_login()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "app",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch, gradio as gr, tempfile, soundfile as sf, numpy as np, requests, io, re\n",
                "from transformers import AutoModel\n",
                "\n",
                "# Load audio from URL\n",
                "def load_audio_url(url):\n",
                "    r = requests.get(url)\n",
                "    data, sr = sf.read(io.BytesIO(r.content))\n",
                "    return sr, (data * 32768).astype(np.int16) if data.dtype == np.float64 else data\n",
                "\n",
                "# Split text into sentences (supports multiple Indic scripts)\n",
                "def split_sentences(text):\n",
                "    # Split on . ! ? ‡•§ ‡•• and similar punctuation\n",
                "    pattern = r'[.!?‡•§‡••\\n]+'\n",
                "    parts = re.split(pattern, text)\n",
                "    return [p.strip() for p in parts if p.strip()]\n",
                "\n",
                "# Examples\n",
                "EXAMPLES = [\n",
                "    {'name': 'PAN_F (Happy)', 'url': 'https://github.com/AI4Bharat/IndicF5/raw/refs/heads/main/prompts/PAN_F_HAPPY_00002.wav',\n",
                "     'ref_text': '‡®á‡©±‡®ï ‡®ó‡©ç‡®∞‡®æ‡®π‡®ï ‡®®‡©á ‡®∏‡®æ‡®°‡©Ä ‡®¨‡©á‡®Æ‡®ø‡®∏‡®æ‡®≤ ‡®∏‡©á‡®µ‡®æ ‡®¨‡®æ‡®∞‡©á ‡®¶‡®ø‡®≤‡©ã‡®Ç‡®ó‡®µ‡®æ‡®π‡©Ä ‡®¶‡®ø‡©±‡®§‡©Ä‡•§',\n",
                "     'synth': '‡§Æ‡•à‡§Ç ‡§¨‡§ø‡§®‡§æ ‡§ï‡§ø‡§∏‡•Ä ‡§ö‡§ø‡§Ç‡§§‡§æ ‡§ï‡•á ‡§Ö‡§™‡§®‡•á ‡§¶‡•ã‡§∏‡•ç‡§§‡•ã‡§Ç ‡§ï‡•ã ‡§≠‡•á‡§ú‡§§‡§æ ‡§π‡•Ç‡§Å‡•§ ‡§µ‡§π ‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§â‡§®‡§ï‡•Ä ‡§Æ‡§¶‡§¶ ‡§ï‡§∞‡•á‡§ó‡§æ‡•§ ‡§Ø‡§π ‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ö‡•ç‡§õ‡•Ä ‡§¨‡§æ‡§§ ‡§π‡•à‡•§'},\n",
                "    {'name': 'TAM_F (Happy)', 'url': 'https://github.com/AI4Bharat/IndicF5/raw/refs/heads/main/prompts/TAM_F_HAPPY_00001.wav',\n",
                "     'ref_text': '‡Æ®‡Ææ‡Æ©‡Øç ‡Æ®‡ØÜ‡Æ©‡Æö‡Øç‡Æö ‡ÆÆ‡Ææ‡Æ§‡Æø‡Æ∞‡Æø‡ÆØ‡Øá ‡ÆÖ‡ÆÆ‡Øá‡Æö‡Ææ‡Æ©‡Øç‡Æ≤ ‡Æ™‡ØÜ‡Æ∞‡Æø‡ÆØ ‡Æ§‡Æ≥‡Øç‡Æ≥‡ØÅ‡Æ™‡Æü‡Æø ‡Æµ‡Æ®‡Øç‡Æ§‡Æø‡Æ∞‡ØÅ‡Æï‡Øç‡Æï‡ØÅ.',\n",
                "     'synth': '‡¥≠‡¥ï‡µç‡¥∑‡¥£‡¥§‡µç‡¥§‡¥ø‡¥®‡µç ‡¥∂‡µá‡¥∑‡¥Ç ‡¥§‡µà‡¥∞‡µç ‡¥∏‡¥æ‡¥¶‡¥Ç ‡¥ï‡¥¥‡¥ø‡¥ö‡µç‡¥ö‡¥æ‡µΩ ‡¥®‡¥≤‡µç‡¥≤‡¥§‡¥æ‡¥£‡µç. ‡¥á‡¥§‡µç ‡¥Ü‡¥∞‡µã‡¥ó‡µç‡¥Ø‡¥§‡µç‡¥§‡¥ø‡¥®‡µç ‡¥®‡¥≤‡µç‡¥≤‡¥§‡¥æ‡¥£‡µç.'},\n",
                "    {'name': 'KAN_F (Happy)', 'url': 'https://github.com/AI4Bharat/IndicF5/raw/refs/heads/main/prompts/KAN_F_HAPPY_00001.wav',\n",
                "     'ref_text': '‡≤®‡≤Æ‡≥ç‚Äå ‡≤´‡≥ç‡≤∞‡≤ø‡≤ú‡≥ç‡≤ú‡≤≤‡≥ç‡≤≤‡≤ø ‡≤ï‡≥Ç‡≤≤‡≤ø‡≤Ç‡≤ó‡≥ç‚Äå ‡≤∏‡≤Æ‡≤∏‡≥ç‡≤Ø‡≥Ü ‡≤Ü‡≤ó‡≤ø‡≤§‡≥ç‡≤§‡≥Å.',\n",
                "     'synth': '‡¶ö‡ßá‡¶®‡ßç‡¶®‡¶æ‡¶á‡¶Ø‡¶º‡ßá‡¶∞ ‡¶Ö‡¶ü‡ßã‡¶§‡ßá ‡¶≤‡ßã‡¶ï‡ßá‡¶∞‡¶æ ‡¶ñ‡¶æ‡¶¨‡¶æ‡¶∞ ‡¶≠‡¶æ‡¶ó ‡¶ï‡¶∞‡ßá ‡¶ñ‡¶æ‡¶Ø‡¶º‡•§ ‡¶è‡¶ü‡¶æ ‡¶Ü‡¶Æ‡¶æ‡¶∞ ‡¶ñ‡ßÅ‡¶¨ ‡¶≠‡¶æ‡¶≤‡ßã ‡¶≤‡¶æ‡¶ó‡ßá‡•§ ‡¶Æ‡¶æ‡¶®‡ßÅ‡¶∑‡ßá‡¶∞ ‡¶è‡¶á ‡¶≠‡¶æ‡¶≤‡ßã‡¶¨‡¶æ‡¶∏‡¶æ ‡¶¶‡ßá‡¶ñ‡ßá ‡¶Æ‡¶® ‡¶≠‡¶∞‡ßá ‡¶Ø‡¶æ‡¶Ø‡¶º‡•§'},\n",
                "]\n",
                "\n",
                "print('Loading examples...')\n",
                "for ex in EXAMPLES:\n",
                "    ex['sr'], ex['data'] = load_audio_url(ex['url'])\n",
                "print('‚úÖ Examples loaded')\n",
                "\n",
                "print('Loading IndicF5...')\n",
                "model = AutoModel.from_pretrained('ai4bharat/IndicF5', trust_remote_code=True)\n",
                "model = model.to('cuda')\n",
                "print('‚úÖ Model loaded')\n",
                "\n",
                "# STREAMING synthesis - yields audio progressively\n",
                "def synthesize_streaming(text, ref_audio, ref_text):\n",
                "    if not text or ref_audio is None or not ref_text:\n",
                "        yield None\n",
                "        return\n",
                "    \n",
                "    sr, data = ref_audio\n",
                "    sentences = split_sentences(text)\n",
                "    print(f'[STREAMING] {len(sentences)} sentences to process')\n",
                "    \n",
                "    # Save reference audio once\n",
                "    with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp:\n",
                "        sf.write(tmp.name, data, sr)\n",
                "        ref_path = tmp.name\n",
                "    \n",
                "    all_audio = np.array([], dtype=np.float32)\n",
                "    \n",
                "    for i, sentence in enumerate(sentences):\n",
                "        print(f'[{i+1}/{len(sentences)}] Generating: {sentence[:50]}...')\n",
                "        \n",
                "        # Generate audio for this sentence\n",
                "        chunk = model(sentence, ref_audio_path=ref_path, ref_text=ref_text)\n",
                "        \n",
                "        # Convert to float32 if needed\n",
                "        if chunk.dtype == np.int16:\n",
                "            chunk = chunk.astype(np.float32) / 32768.0\n",
                "        \n",
                "        # Accumulate audio\n",
                "        all_audio = np.concatenate([all_audio, chunk])\n",
                "        \n",
                "        # Yield accumulated audio so far\n",
                "        print(f'[{i+1}/{len(sentences)}] Yielding {len(all_audio)} samples')\n",
                "        yield (24000, all_audio.copy())\n",
                "    \n",
                "    print('[STREAMING] Complete!')\n",
                "\n",
                "def load_example(name):\n",
                "    ex = next((e for e in EXAMPLES if e['name'] == name), None)\n",
                "    if ex:\n",
                "        return (ex['sr'], ex['data']), ex['ref_text'], ex['synth']\n",
                "    return None, '', ''\n",
                "\n",
                "# Build Gradio UI\n",
                "with gr.Blocks(title='IndicF5 Streaming') as app:\n",
                "    gr.Markdown('# üéß IndicF5 Streaming TTS\\n*Audio starts playing after first sentence!*')\n",
                "    \n",
                "    example_dropdown = gr.Dropdown([e['name'] for e in EXAMPLES], label='üìÇ Load Example')\n",
                "    \n",
                "    with gr.Row():\n",
                "        with gr.Column():\n",
                "            txt = gr.Textbox(label='Text to synthesize', lines=4, placeholder='Enter text with multiple sentences...')\n",
                "            ref = gr.Audio(label='Reference Audio', type='numpy')\n",
                "            ref_txt = gr.Textbox(label='Reference Text')\n",
                "            btn = gr.Button('üé§ Generate (Streaming)', variant='primary')\n",
                "        \n",
                "        # STREAMING audio output\n",
                "        out = gr.Audio(label='Output (streams as sentences complete)', streaming=True, autoplay=True)\n",
                "    \n",
                "    example_dropdown.change(load_example, [example_dropdown], [ref, ref_txt, txt])\n",
                "    btn.click(synthesize_streaming, [txt, ref, ref_txt], [out])\n",
                "\n",
                "app.launch(share=True, debug=True)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}