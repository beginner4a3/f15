{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "8dd52724",
            "metadata": {},
            "source": [
                "# IndicF5 Gradio Demo\n",
                "\n",
                "This notebook requires a **GPU runtime**. Go to **Runtime → Change runtime type → T4 GPU** before running."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "gpu_check",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check GPU availability - THIS MODEL REQUIRES GPU\n",
                "import torch\n",
                "if not torch.cuda.is_available():\n",
                "    raise RuntimeError('❌ GPU not available! Go to Runtime → Change runtime type → T4 GPU')\n",
                "print(f'✅ GPU available: {torch.cuda.get_device_name(0)}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "disable_dynamo",
            "metadata": {},
            "outputs": [],
            "source": [
                "# CRITICAL: Disable torch.compile/dynamo BEFORE any model loads\n",
                "# This fixes the silent audio bug\n",
                "import os\n",
                "os.environ['TORCH_COMPILE_DISABLE'] = '1'\n",
                "os.environ['TORCHDYNAMO_DISABLE'] = '1'\n",
                "\n",
                "import torch\n",
                "import torch._dynamo\n",
                "torch._dynamo.config.suppress_errors = True\n",
                "torch._dynamo.disable()\n",
                "\n",
                "# Make torch.compile a no-op\n",
                "original_compile = torch.compile\n",
                "torch.compile = lambda model, *args, **kwargs: model\n",
                "\n",
                "print('✅ torch.compile/dynamo disabled')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "clear_cache",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clear HuggingFace cache\n",
                "!rm -rf ~/.cache/huggingface/modules/\n",
                "print('✅ HuggingFace modules cache cleared')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "clone_cell",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clone the repository (fresh clone)\n",
                "import os\n",
                "!rm -rf f15\n",
                "!git clone https://github.com/beginner4a3/f15\n",
                "os.chdir('f15')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e87c2428",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install compatible library versions\n",
                "%pip install -q 'transformers<4.50' accelerate\n",
                "%pip install -q git+https://github.com/ai4bharat/IndicF5.git\n",
                "%pip install -q gradio spaces huggingface_hub torchcodec"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "patch_app",
            "metadata": {},
            "outputs": [],
            "source": [
                "# PATCH: Fix app.py\n",
                "with open('app.py', 'r') as f:\n",
                "    content = f.read()\n",
                "\n",
                "# Disable torch.compile\n",
                "content = content.replace(\n",
                "    'if hasattr(torch, \"compile\"):',\n",
                "    'if False:'\n",
                ")\n",
                "\n",
                "# Enable share=True\n",
                "content = content.replace(\n",
                "    'iface.launch()',\n",
                "    'iface.launch(share=True, debug=True)'\n",
                ")\n",
                "\n",
                "# Fix deprecated autocast\n",
                "content = content.replace(\n",
                "    'torch.cuda.amp.autocast(enabled=True)',\n",
                "    \"torch.amp.autocast('cuda', enabled=True)\"\n",
                ")\n",
                "\n",
                "with open('app.py', 'w') as f:\n",
                "    f.write(content)\n",
                "\n",
                "print('✅ app.py patched')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "hf_login",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Login to Hugging Face (optional)\n",
                "from huggingface_hub import notebook_login\n",
                "notebook_login()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "run_app",
            "metadata": {},
            "outputs": [],
            "source": [
                "# IMPORTANT: Set env vars again before running\n",
                "import os\n",
                "os.environ['TORCH_COMPILE_DISABLE'] = '1'\n",
                "os.environ['TORCHDYNAMO_DISABLE'] = '1'\n",
                "\n",
                "# Run the app\n",
                "!TORCH_COMPILE_DISABLE=1 TORCHDYNAMO_DISABLE=1 python app.py"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}